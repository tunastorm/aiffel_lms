{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "driving-bearing",
   "metadata": {},
   "source": [
    "## 가위바위보_구별기\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-consequence",
   "metadata": {},
   "source": [
    "### 반복 사용되는 모듈 임포트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "private-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob, cv2\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-teach",
   "metadata": {},
   "source": [
    "### 가위, 바위, 보 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "blank-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path): \n",
    "    for folder in os.listdir(img_path):\n",
    "        if folder not in ['rock', 'scissor', 'paper']: \n",
    "            continue   \n",
    "        images=glob.glob(img_path + f\"/{folder}/*.jpg\")  \n",
    "        print(f\"{len(images)} {folder} images to be resized.\")\n",
    "        # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "        target_size=(28,28)\n",
    "        for img in images:\n",
    "            old_img=cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "            new_img=cv2.resize(old_img,target_size,Image.ANTIALIAS)\n",
    "            cv2.imwrite(img,new_img)\n",
    "        print(f\"{len(images)} {folder} images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "southeast-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/train 중 하나를 입력하세요test\n",
      "92 paper images to be resized.\n",
      "92 paper images resized.\n",
      "77 rock images to be resized.\n",
      "77 rock images resized.\n",
      "66 scissor images to be resized.\n",
      "66 scissor images resized.\n",
      "test 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "folder_name = input(\"test/train 중 하나를 입력하세요\")\n",
    "image_dir_path = os.getenv(\"HOME\") + f\"/aiffel/rock_scissor_paper/{folder_name}\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(f\"{folder_name} 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-riding",
   "metadata": {},
   "source": [
    "### 전처리된 이미지 행렬화 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "moved-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=1\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size, color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "     \n",
    "    # number_of_data를 3분의 1로 나눠 가위/바위/보를 균등하게 채움   \n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        if idx > (number_of_data//3)-1: # 가위 이미지의 개수상한 초과시 추가하지 않음.\n",
    "            continue\n",
    "        img = np.array(Image.open(file),dtype=np.uint8).reshape(28,28,1)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        if idx > (number_of_data//3*2)-1: # 바위 이미지의 개수상한 초과시 추가하지 않음.\n",
    "            continue\n",
    "        img = np.array(Image.open(file),dtype=np.uint8).reshape(28,28,1)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "\n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        if idx > number_of_data-1:  # 보 이미지의 개수상한 초과시 추가하지 않음.\n",
    "            continue\n",
    "        img = np.array(Image.open(file),dtype=np.uint8).reshape(28,28,1)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(f\"처리된 데이터의 이미지 개수는 {idx}개 입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "numeric-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test 중 하나를 입력하세요train\n",
      "처리된 데이터의 이미지 개수는 3207개 입니다.\n",
      "x_train shape: (3300, 28, 28, 1)\n",
      "y_train shape: (3300,)\n"
     ]
    }
   ],
   "source": [
    "folder_name = input(\"train/test 중 하나를 입력하세요\")\n",
    "image_dir_path = os.getenv(\"HOME\") + f\"/aiffel/rock_scissor_paper/{folder_name}\"\n",
    "if folder_name == \"train\":\n",
    "    (x_train, y_train)=load_data(image_dir_path,3300)\n",
    "    x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "    x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  # 정규화된 이미지 reshape\n",
    "    print(f\"x_train shape: {x_train_reshaped.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "else: \n",
    "    (x_test, y_test)=load_data(image_dir_path)\n",
    "    x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "    x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  # 정규화된 이미지 reshape\n",
    "    x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 1)\n",
    "    print(f\"x_test reshaped: {x_test_reshaped.shape}\")\n",
    "    print(f\"y_test reshaped: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-implementation",
   "metadata": {},
   "source": [
    "### 학습 모델만들기  \n",
    "\n",
    "[컨볼루션 신경망 레이어 이야기](https://tykimos.github.io/2017/01/27/CNN_Layer_Talk/)를 참조하여 실습을 진행했다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "wound-scanner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 25, 25, 16)        272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 9, 9, 16)          4112      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 39,344\n",
      "Trainable params: 39,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, MaxPooling2D, Flatten, Dense\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "#4X4크기의 필터 16개를 쌓고, 입력 이미지의 크기를 28X28X1로 지정한다.  \n",
    "model.add(Conv2D(16, (4,4), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(16, (4,4), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "# 입력뉴런 4개 출력뉴런 128개인 Dense레이어를 model에 추가           \n",
    "model.add(Dense(128, activation='relu', input_dim=4))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-stockholm",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "neither-capitol",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "104/104 [==============================] - 1s 3ms/step - loss: 1.5631 - accuracy: 0.3415\n",
      "Epoch 2/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 1.0140 - accuracy: 0.4451\n",
      "Epoch 3/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.8783 - accuracy: 0.5644\n",
      "Epoch 4/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.7846 - accuracy: 0.6363\n",
      "Epoch 5/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.7209\n",
      "Epoch 6/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7514\n",
      "Epoch 7/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.8163\n",
      "Epoch 8/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.8320\n",
      "Epoch 9/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8322\n",
      "Epoch 10/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8534\n",
      "Epoch 11/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8687\n",
      "Epoch 12/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8831\n",
      "Epoch 13/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.9067\n",
      "Epoch 14/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.2428 - accuracy: 0.9135\n",
      "Epoch 15/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9195\n",
      "Epoch 16/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9203\n",
      "Epoch 17/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.1845 - accuracy: 0.9364\n",
      "Epoch 18/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.9101\n",
      "Epoch 19/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9464\n",
      "Epoch 20/20\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f82740507d0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델이 20번 학습한다.                                      \n",
    "model.fit(x_train_reshaped, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-forestry",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "numerous-blade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 2.1581 - accuracy: 0.6433\n",
      "test_loss: 2.158133029937744\n",
      "test_accuracy: 0.6433333158493042\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(f'test_loss: {test_loss}')\n",
    "print(f'test_accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-europe",
   "metadata": {},
   "source": [
    "## 후기\n",
    "-----\n",
    "이번 과제를 수행하는 동안 어려웠던 점은 역시 **accuracy 60을 넘기는 것**이었다.\n",
    "\n",
    "도중에 여러번 60을 넘긴 경우가 있었지만, 참지못하고 다시 시도하는 바람에 다시 60을 만들기까지 긴 시간이 걸렸다.\n",
    "\n",
    "하지만 그러면서 여러가지 시도를 하다보니 배우게 된 부분 역시 많았다.\n",
    "\n",
    "<br>\n",
    "\n",
    "1. cv2 모듈을 활용한 이미지파일 그레이스케일 처리\n",
    "\n",
    "2. 인공신경망의 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-establishment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
